{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70142ef4-3634-4488-b630-59db931c3b60",
   "metadata": {},
   "source": [
    "### TSP Policy-Based RL Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09b2acb8-783e-48b8-956a-9d88a1f12dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # %%\n",
    "# # Imports & Setup\n",
    "# import os\n",
    "# import glob\n",
    "# import time\n",
    "# import math\n",
    "# import random\n",
    "# import numpy as np\n",
    "\n",
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.nn.functional as F\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# from TSProblemDef import augment_xy_data_by_8_fold, get_random_problems\n",
    "# from utils.utils import TimeEstimator\n",
    "\n",
    "# # Device\n",
    "# device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "# torch.set_default_tensor_type('torch.cuda.FloatTensor' if device.type=='cuda' else 'torch.FloatTensor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "761ab602-a2bf-4618-8bb0-a7360451f321",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %% [markdown]\n",
    "# ## Environment Definition (TSPEnv)\n",
    "\n",
    "class ResetState:\n",
    "    def __init__(self, problems):\n",
    "        self.problems = problems  # (batch, problem_size, 2)\n",
    "\n",
    "class StepState:\n",
    "    def __init__(self, BATCH_IDX, POMO_IDX, ninf_mask):\n",
    "        self.BATCH_IDX = BATCH_IDX\n",
    "        self.POMO_IDX = POMO_IDX\n",
    "        self.current_node = None\n",
    "        self.ninf_mask = ninf_mask\n",
    "\n",
    "class TSPEnv:\n",
    "    def __init__(self, problem_size, pomo_size):\n",
    "        self.problem_size = problem_size\n",
    "        self.pomo_size = pomo_size\n",
    "\n",
    "    def load_problems(self, batch_size, aug_factor=1):\n",
    "        self.batch_size = batch_size\n",
    "        self.problems = get_random_problems(batch_size, self.problem_size)\n",
    "        if aug_factor == 8:\n",
    "            self.batch_size *= 8\n",
    "            self.problems = augment_xy_data_by_8_fold(self.problems)\n",
    "        self.BATCH_IDX = torch.arange(self.batch_size)[:,None].expand(self.batch_size, self.pomo_size)\n",
    "        self.POMO_IDX  = torch.arange(self.pomo_size)[None,:].expand(self.batch_size, self.pomo_size)\n",
    "\n",
    "    def reset(self):\n",
    "        self.selected_count = 0\n",
    "        self.current_node = None\n",
    "        self.selected_node_list = torch.zeros((self.batch_size, self.pomo_size, 0), dtype=torch.long)\n",
    "        mask = torch.zeros((self.batch_size, self.pomo_size, self.problem_size))\n",
    "        self.step_state = StepState(self.BATCH_IDX, self.POMO_IDX, mask)\n",
    "        return ResetState(self.problems), None, False\n",
    "\n",
    "    def pre_step(self):\n",
    "        return self.step_state, None, False\n",
    "\n",
    "    def step(self, selected):\n",
    "        self.selected_count += 1\n",
    "        self.current_node = selected\n",
    "        self.selected_node_list = torch.cat((self.selected_node_list, selected[:,:,None]), dim=2)\n",
    "        self.step_state.current_node = selected\n",
    "        m = self.step_state.ninf_mask\n",
    "        m[self.BATCH_IDX, self.POMO_IDX, selected] = float('-inf')\n",
    "        done = (self.selected_count == self.problem_size)\n",
    "        reward = -self._get_travel_distance() if done else None\n",
    "        return self.step_state, reward, done\n",
    "\n",
    "    def _get_travel_distance(self):\n",
    "        coords = self.problems\n",
    "        order = self.selected_node_list.unsqueeze(3).expand(self.batch_size, -1, self.problem_size, 2)\n",
    "        seq = coords[:,None,:,:].expand(self.batch_size, self.pomo_size, self.problem_size, 2)\n",
    "        ordered = seq.gather(2, order)\n",
    "        rolled = ordered.roll(dims=2, shifts=-1)\n",
    "        seg = ((ordered - rolled)**2).sum(3).sqrt()\n",
    "        return seg.sum(2)\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Transformer Encoder Model\n",
    "\n",
    "def reshape_by_heads(x, head_num):\n",
    "    B,n,_ = x.size()\n",
    "    return x.view(B,n,head_num,-1).transpose(1,2)\n",
    "\n",
    "class AddNorm(nn.Module):\n",
    "    def __init__(self, emb):\n",
    "        super().__init__()\n",
    "        self.norm = nn.InstanceNorm1d(emb, affine=True)\n",
    "    def forward(self, x, sub):\n",
    "        y = x + sub\n",
    "        return self.norm(y.transpose(1,2)).transpose(1,2)\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, emb, hidden):\n",
    "        super().__init__()\n",
    "        self.w1 = nn.Linear(emb, hidden)\n",
    "        self.w2 = nn.Linear(hidden, emb)\n",
    "    def forward(self, x):\n",
    "        return self.w2(F.relu(self.w1(x)))\n",
    "\n",
    "class TSP_Encoder(nn.Module):\n",
    "    def __init__(self, embedding_dim, encoder_layer_num, head_num, qkv_dim, ff_hidden_dim, **_):\n",
    "        super().__init__()\n",
    "        self.embed = nn.Linear(2, embedding_dim)\n",
    "        self.layers = nn.ModuleList()\n",
    "        for _ in range(encoder_layer_num):\n",
    "            self.layers.append(nn.ModuleDict({\n",
    "                'Wq': nn.Linear(embedding_dim, head_num*qkv_dim, bias=False),\n",
    "                'Wk': nn.Linear(embedding_dim, head_num*qkv_dim, bias=False),\n",
    "                'Wv': nn.Linear(embedding_dim, head_num*qkv_dim, bias=False),\n",
    "                'combine': nn.Linear(head_num*qkv_dim, embedding_dim),\n",
    "                'addnorm1': AddNorm(embedding_dim),\n",
    "                'ff': FeedForward(embedding_dim, ff_hidden_dim),\n",
    "                'addnorm2': AddNorm(embedding_dim)\n",
    "            }))\n",
    "        self.head_num = head_num\n",
    "\n",
    "    def forward(self, coords):\n",
    "        x = self.embed(coords)\n",
    "        for l in self.layers:\n",
    "            q = reshape_by_heads(l['Wq'](x), self.head_num)\n",
    "            k = reshape_by_heads(l['Wk'](x), self.head_num)\n",
    "            v = reshape_by_heads(l['Wv'](x), self.head_num)\n",
    "            dim = q.size(-1)\n",
    "            scores = torch.matmul(q, k.transpose(-2,-1)) / math.sqrt(dim)\n",
    "            att = torch.matmul(F.softmax(scores, dim=-1), v)\n",
    "            att = att.transpose(1,2).contiguous().view(x.size(0), x.size(1), -1)\n",
    "            att = l['combine'](att)\n",
    "            x = l['addnorm1'](x, att)\n",
    "            ff = l['ff'](x)\n",
    "            x = l['addnorm2'](x, ff)\n",
    "        return x\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Instance Loading Helpers\n",
    "\n",
    "def load_npz_instances(N, count):\n",
    "    files = glob.glob(f'data/TSP{N}/instances/*.npz')\n",
    "    chosen = random.sample(files, count)\n",
    "    data = []\n",
    "    for f in chosen:\n",
    "        arr = np.load(f)['coords']\n",
    "        data.append(torch.from_numpy(arr).float())\n",
    "    return torch.stack(data,0)\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Training with Curriculum\n",
    "\n",
    "# Hyperparams\n",
    "model_params = {\n",
    "    'embedding_dim':128, 'encoder_layer_num':3,\n",
    "    'head_num':8, 'qkv_dim':64, 'ff_hidden_dim':512,\n",
    "    'sqrt_embedding_dim':math.sqrt(128), 'logit_clipping':10.0\n",
    "}\n",
    "env_params = {'problem_size':20, 'pomo_size':10}\n",
    "opt_params = {'lr':1e-4, 'betas':(0.9,0.999), 'weight_decay':1e-4}\n",
    "sched_params = {'milestones':[20000,50000], 'gamma':0.5}\n",
    "train_params = {'batch_size':512, 'log_interval':1000}\n",
    "curriculum = [\n",
    "    {'sizes':[10,20], 'steps':10000},\n",
    "    {'sizes':[20,30,40], 'steps':30000},\n",
    "    {'sizes':[30,40,50], 'steps':60000}\n",
    "]\n",
    "\n",
    "env = TSPEnv(**env_params)\n",
    "encoder = TSP_Encoder(**model_params).to(device)\n",
    "opt = torch.optim.Adam(encoder.parameters(), **opt_params)\n",
    "sched = torch.optim.lr_scheduler.MultiStepLR(opt, **sched_params)\n",
    "\n",
    "time_est = TimeEstimator()\n",
    "steps, loss_log, dist_log = [], [], []\n",
    "global_step, start = 0, time.time()\n",
    "\n",
    "def policy_head(q, emb, mask):\n",
    "    logits = torch.matmul(q, emb.transpose(1,2))\n",
    "    logits = logits / model_params['sqrt_embedding_dim']\n",
    "    logits = model_params['logit_clipping']*torch.tanh(logits)\n",
    "    logits = logits + mask\n",
    "    return F.softmax(logits, dim=-1)\n",
    "\n",
    "for stage in curriculum:\n",
    "    for _ in range(stage['steps']):\n",
    "        global_step +=1\n",
    "        sz = random.choice(stage['sizes'])\n",
    "        env.problem_size = sz\n",
    "        env.load_problems(train_params['batch_size'])\n",
    "        state,_,_ = env.reset()\n",
    "        emb = encoder(state.problems.to(device))\n",
    "        B,P = train_params['batch_size'], env.pomo_size\n",
    "        first = torch.arange(P,device=device).unsqueeze(0).repeat(B,1)\n",
    "        q = emb.gather(1, first[:,:,None].expand(-1,-1,model_params['embedding_dim']))\n",
    "        mask = torch.zeros((B,P,sz),device=device)\n",
    "        logs, done = [], False\n",
    "        while not done:\n",
    "            probs = policy_head(q, emb, mask)\n",
    "            idx = probs.reshape(B*P,-1).multinomial(1).view(B,P)\n",
    "            logs.append(torch.log(probs[torch.arange(B)[:,None], torch.arange(P)[None,:], idx]))\n",
    "            state, reward, done = env.step(idx)\n",
    "            mask = state.ninf_mask.to(device)\n",
    "            q = emb.gather(1, state.current_node[:,:,None].expand(-1,-1,model_params['embedding_dim']))\n",
    "        r = reward.to(device)\n",
    "        adv = r - r.mean(1,keepdim=True)\n",
    "        lp = torch.stack(logs,2).sum(2)\n",
    "        loss = -(adv*lp).mean()\n",
    "        opt.zero_grad(); loss.backward(); opt.step(); sched.step()\n",
    "        if global_step%train_params['log_interval']==0:\n",
    "            avgd = -r.max(1)[0].mean().item()\n",
    "            print(f\"Step {global_step} | Sz {sz} | Loss {loss.item():.4f} | Dist {avgd:.4f} | Elap {time.time()-start:.1f}s\")\n",
    "            steps.append(global_step); loss_log.append(loss.item()); dist_log.append(avgd)\n",
    "    # stage eval on 20\n",
    "    test = load_npz_instances(20,20).to(device)\n",
    "    d=[]\n",
    "    for inst in test:\n",
    "        env.problems = inst.unsqueeze(0)\n",
    "        env.batch_size=1\n",
    "        env.BATCH_IDX=torch.zeros((1,env.pomo_size),dtype=torch.long)\n",
    "        env.POMO_IDX=torch.arange(env.pomo_size)[None,:]\n",
    "        state,_,_=env.reset()\n",
    "        emb=encoder(state.problems.to(device))\n",
    "        B,P=1,env.pomo_size\n",
    "        first=torch.arange(P,device=device).unsqueeze(0)\n",
    "        q=emb.gather(1, first[:,:,None].expand(-1,-1,model_params['embedding_dim']))\n",
    "        mask=torch.zeros((B,P,20),device=device)\n",
    "        done=False\n",
    "        while not done:\n",
    "            probs=policy_head(q,emb,mask)\n",
    "            idx=probs.argmax(dim=2)\n",
    "            state,reward,done=env.step(idx)\n",
    "            mask=state.ninf_mask.to(device)\n",
    "            q=emb.gather(1,state.current_node[:,:,None].expand(-1,-1,model_params['embedding_dim']))\n",
    "        d.append((-reward).item())\n",
    "    print(f\"Stage eval avg dist: {sum(d)/len(d):.4f}\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Plot Learning Curve\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.plot(steps, dist_log)\n",
    "plt.title('Avg Tour Length')\n",
    "plt.xlabel('Steps'); plt.ylabel('Distance')\n",
    "plt.show()\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Final Evaluation\n",
    "\n",
    "coords20 = load_npz_instances(20,100).to(device)\n",
    "coords50 = load_npz_instances(50,100).to(device)\n",
    "for N, data in [(20,coords20),(50,coords50)]:\n",
    "    d=[]\n",
    "    for inst in data:\n",
    "        env.problems=inst.unsqueeze(0)\n",
    "        env.batch_size=1\n",
    "        env.BATCH_IDX=torch.zeros((1,env.pomo_size),dtype=torch.long)\n",
    "        env.POMO_IDX=torch.arange(env.pomo_size)[None,:]\n",
    "        state,_,_=env.reset()\n",
    "        emb=encoder(state.problems.to(device))\n",
    "        B,P=1,env.pomo_size\n",
    "        first=torch.arange(P,device=device).unsqueeze(0)\n",
    "        q=emb.gather(1, first[:,:,None].expand(-1,-1,model_params['embedding_dim']))\n",
    "        mask=torch.zeros((B,P,N),device=device)\n",
    "        done=False\n",
    "        while not done:\n",
    "            probs=policy_head(q,emb,mask)\n",
    "            idx=probs.argmax(dim=2)\n",
    "            state,reward,done=env.step(idx)\n",
    "            mask=state.ninf_mask.to(device)\n",
    "            q=emb.gather(1,state.current_node[:,:,None].expand(-1,-1,model_params['embedding_dim']))\n",
    "        d.append((-reward).item())\n",
    "    print(f\"Final {N}-city avg dist: {sum(d)/len(d):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb2a035-9122-4811-8146-f6b04d29fc7d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
